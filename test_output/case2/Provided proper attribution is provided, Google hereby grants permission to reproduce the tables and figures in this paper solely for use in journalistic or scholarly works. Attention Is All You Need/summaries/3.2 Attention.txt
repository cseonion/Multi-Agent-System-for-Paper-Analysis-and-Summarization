Section 3.2 defines attention as a function that takes a query and a set of keyâ€“value pairs and yields an output vector. All inputs and the output are vectors. The output is produced as a weighted sum of the values, with weights derived from a compatibility score between the query and each key; this mechanism is implemented as scaled dot-product attention and extended to multi-head attention, which runs multiple attention mechanisms in parallel.