Section 3 articulates design requirements for enabling novice users to creatively express themselves with text-to-audio music generation, guided by human–computer interaction principles. The authors used a think-aloud protocol with three volunteers who reported no formal musical training beyond compulsory education, giving them access to one of the latest text-to-audio models in Google Colab via its official implementation. The users could input any text prompts and listen to three generated music outputs; the participants, Japanese speakers, were advised to use DeepL Translator to translate prompts into English to better align with the model’s English-trained labels. Over roughly 30 minutes of free exploration—with screen sharing and verbalized thoughts—the study identified challenges and contributing factors, which were then validated and enriched through semistructured interviews. The responses were analyzed with open coding, yielding design requirements that align with the broader creativity-support literature.