Section 5 shows that retrieval-based exemplars outperform the original user-prompt baseline (User) in both automatic metrics and human evaluation (Table 1), with consistent improvements and a reduced r div when guided by demonstrations. To verify that gains are not solely from LLM prompt editing, exemplar (K=100, closest) is contrasted with LLM, yielding a textâ€“audio alignment gain of +0.011 (CLAP) and a further FAD improvement of +2.125. The study also tests the hypothesis that the most similar exemplars are best by comparing exemplar (K=100, farthest) and exemplar (K=100, random), with closest exemplars described as more distinct and displaying the highest token-type ratio (Table 2). Overall, exemplar-based editing achieves higher agreement than other editing techniques (Table 2). The greatest audio improvement arises from LLM editing with in-context learning, which even outperforms pure LLM editing by up to +0.23 in subjective human evaluation.