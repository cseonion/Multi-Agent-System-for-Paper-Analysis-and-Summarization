import json
from pathlib import Path
from langchain_openai import ChatOpenAI
import logging

logger = logging.getLogger(__name__)


def load_agent_config():
    """agent_config.json íŒŒì¼ì—ì„œ ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    config_path = Path(__file__).parent / "agent_config.json"
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        # logger.info(f"âœ… Agent ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {config_path}")
        return config
    except FileNotFoundError:
        logger.error(f"âŒ Agent ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
        return {}
    except json.JSONDecodeError as e:
        logger.error(f"âŒ Agent ì„¤ì • íŒŒì¼ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return {}


def get_llm(agent_name: str) -> ChatOpenAI:
    """
    íŠ¹ì • agentì˜ LLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    config = load_agent_config()
    llm_configs = config.get("llm_models", {})

    # ê¸°ë³¸ê°’
    default_kwargs = {"model": "gpt-4.1-mini", "temperature": 0}
    agent_config = llm_configs.get(agent_name, default_kwargs)

    # None ê°’ í•„í„°ë§
    kwargs = {k: v for k, v in agent_config.items() if v is not None}

    logger.info(f"ğŸ”§ {agent_name} LLM ìƒì„±: {kwargs}")
    base_llm = ChatOpenAI(**kwargs)

    # í† í° ì¶”ì  ì½œë°± ì—°ê²°
    try:
        from src.tracking import get_langchain_callback
        cb = get_langchain_callback()
        if cb is not None:
            return base_llm.with_config(callbacks=[cb])
    except Exception:
        pass
    return base_llm
