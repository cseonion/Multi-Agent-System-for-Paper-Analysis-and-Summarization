import os
import re
import logging
from typing import Dict, List, Any, Sequence, Annotated, cast
import operator
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
from src.tracking import track_agent

from src.state import State, SummaryState

# LLM ëª¨ë¸ ì •ì˜
## ì„¹ì…˜ ìš”ì•½ LLM
SECTION_SUMMARY_LLM = ChatOpenAI(
    model="gpt-4.1-mini",
    temperature=0.1,
    max_tokens=2000
)
## ìµœì¢… ìš”ì•½ LLM
FINAL_SUMMARY_LLM = ChatOpenAI(
    model="gpt-4.1",
    temperature=0.1,
    max_tokens=10000
)

# í˜„ì¬ ëª¨ë“ˆ ë¡œê±° ìƒì„± (main.pyì—ì„œ ì„¤ì •í•œ ë¡œê¹… ì‚¬ìš©)
logger = logging.getLogger(__name__)

def print_completion_message(paper_title: str, stage: str, details: str = ""):
    """
    ë‹¨ìˆœí•œ ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥ í•¨ìˆ˜
    
    Args:
        paper_title: ë…¼ë¬¸ ì œëª©
        stage: ì²˜ë¦¬ ë‹¨ê³„ (ì˜ˆ: "ì„¹ì…˜ ì¶”ì¶œ", "ì„¹ì…˜ ìš”ì•½", "ìµœì¢… ìš”ì•½")
        details: ì¶”ê°€ ì •ë³´ (ì˜ˆ: ì„¹ì…˜ ê°œìˆ˜)
    """
    short_title = paper_title[:50] + "..." if len(paper_title) > 50 else paper_title
    message = f"âœ… '{short_title}' {stage} ì™„ë£Œ"
    if details:
        message += f" ({details})"
    print(message)

class SummaryFileManager:
    """ìš”ì•½ íŒŒì¼ ì €ì¥ ë° ê´€ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        pass
    
    def _sanitize_filename(self, filename: str) -> str:
        """íŒŒì¼ëª…ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì •ë¦¬"""
        # íŠ¹ìˆ˜ë¬¸ìë¥¼ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
        filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
        # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ë³€ê²½
        filename = re.sub(r'\s+', ' ', filename)
        # ì•ë’¤ ê³µë°± ì œê±°
        filename = filename.strip()
        return filename
    
    def _get_summaries_dir_from_vectorstore_path(self, vectorstore_path: str) -> str:
        """vectorstore_pathì—ì„œ summaries ë””ë ‰í† ë¦¬ ê²½ë¡œ ìƒì„±"""
        # vectorstore_pathì—ì„œ í•œ í´ë” ìœ„ë¡œ ì˜¬ë¼ê°€ê¸°
        # ì˜ˆ: /path/to/datetime/paper_title/vectorstore â†’ /path/to/datetime/paper_title/summaries
        paper_dir = os.path.dirname(vectorstore_path)
        summaries_dir = os.path.join(paper_dir+"/../", "summaries")
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(summaries_dir, exist_ok=True)
        
        return summaries_dir
    
    def save_section_summary(self, paper_title: str, section_number: str, 
                           section_name: str, summary_content: str, vectorstore_path: str) -> str:
        """ê°œë³„ ì„¹ì…˜ ìš”ì•½ì„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥"""
        
        # vectorstore_pathì—ì„œ summaries ë””ë ‰í† ë¦¬ ìƒì„±
        summaries_dir = self._get_summaries_dir_from_vectorstore_path(vectorstore_path)
        
        # íŒŒì¼ëª… ìƒì„±: "section_number section_name.txt"
        filename = f"{section_number} {section_name}.txt"
        safe_filename = self._sanitize_filename(filename)
        
        # ì „ì²´ íŒŒì¼ ê²½ë¡œ
        file_path = os.path.join(summaries_dir, safe_filename)
        
        try:
            # ìš”ì•½ ë‚´ìš©ì„ íŒŒì¼ì— ì €ì¥
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(f"ë…¼ë¬¸ ì œëª©: {paper_title}\n")
                f.write(f"ì„¹ì…˜: {section_number}. {section_name}\n")
                f.write("=" * 50 + "\n\n")
                f.write(summary_content)
                f.write("\n\n")
                f.write("=" * 50 + "\n")
                f.write(f"ìƒì„± ì‹œê°„: {self._get_current_timestamp()}\n")
            
            # ê°œë³„ ì„¹ì…˜ ì €ì¥ ë©”ì‹œì§€ ì œê±° (ì„¹ì…˜ë³„ ìš”ì•½ ì™„ë£Œì‹œì—ë§Œ í‘œì‹œ)
            return file_path
            
        except Exception as e:
            print(f"      âŒ ì„¹ì…˜ ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            return ""
    
    def save_final_summary(self, paper_title: str, final_summary: str, vectorstore_path: str) -> str:
        """ìµœì¢… ìš”ì•½ì„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥"""
        
        # vectorstore_pathì—ì„œ summaries ë””ë ‰í† ë¦¬ ìƒì„±
        summaries_dir = self._get_summaries_dir_from_vectorstore_path(vectorstore_path)
        
        # íŒŒì¼ëª…: "Final_Summary.txt"
        filename = "Final_Summary.txt"
        file_path = os.path.join(summaries_dir, filename)
        
        try:
            # ìµœì¢… ìš”ì•½ì„ íŒŒì¼ì— ì €ì¥
            with open(file_path, 'w', encoding='utf-8') as f:
                # f.write(f"ë…¼ë¬¸ ì œëª©: {paper_title}\n")
                # f.write("=" * 50 + "\n\n")
                f.write(final_summary)
                # f.write("\n\n")
                # f.write("=" * 50 + "\n")
                # f.write(f"ìƒì„± ì‹œê°„: {self._get_current_timestamp()}\n")
            
            print(f"      ğŸ’¾ ìµœì¢… ìš”ì•½ ì €ì¥ë¨: {filename}")
            return file_path
            
        except Exception as e:
            print(f"      âŒ ìµœì¢… ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            return ""
    
    def save_all_summaries_index(self, paper_title: str, section_summaries: List[str], 
                               paper_sections: List[tuple], vectorstore_path: str) -> str:
        """ëª¨ë“  ìš”ì•½ì„ í•˜ë‚˜ì˜ ì¸ë±ìŠ¤ íŒŒì¼ë¡œ ì €ì¥"""
        
        # vectorstore_pathì—ì„œ summaries ë””ë ‰í† ë¦¬ ìƒì„±
        summaries_dir = self._get_summaries_dir_from_vectorstore_path(vectorstore_path)
        
        # íŒŒì¼ëª…: "00 Index_All_Summaries.txt"
        filename = "00 Index_All_Summaries.txt"
        file_path = os.path.join(summaries_dir, filename)
        
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(f"ë…¼ë¬¸ ì œëª©: {paper_title}\n")
                f.write("ì „ì²´ ì„¹ì…˜ë³„ ìš”ì•½ ì¸ë±ìŠ¤\n")
                f.write("=" * 60 + "\n\n")
                
                # ê° ì„¹ì…˜ë³„ ìš”ì•½ ì‘ì„±
                for i, summary in enumerate(section_summaries):
                    if i < len(paper_sections):
                        section_number, section_name = paper_sections[i]
                        f.write(f"ì„¹ì…˜ {section_number}: {section_name}\n")
                    else:
                        f.write(f"ì„¹ì…˜ {i+1}: ì¶”ê°€ ì„¹ì…˜\n")
                    
                    f.write("-" * 40 + "\n")
                    f.write(summary)
                    f.write("\n\n")
                
                f.write("=" * 60 + "\n")
                f.write(f"ì´ ì„¹ì…˜ ìˆ˜: {len(section_summaries)}\n")
                f.write(f"ìƒì„± ì‹œê°„: {self._get_current_timestamp()}\n")
            
            print(f"      ğŸ“‘ ì „ì²´ ìš”ì•½ ì¸ë±ìŠ¤ ì €ì¥ë¨: {filename}")
            return file_path
            
        except Exception as e:
            print(f"      âŒ ì¸ë±ìŠ¤ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            return ""
    
    def _get_current_timestamp(self) -> str:
        """í˜„ì¬ ì‹œê°„ ë¬¸ìì—´ ë°˜í™˜"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


# class PaperSummaryState:
#     """ê°œë³„ ë…¼ë¬¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ ìƒíƒœ í´ë˜ìŠ¤"""
#     def __init__(self, paper_title: str, vectorstore: Any = None, vectorstore_path: str = "", 
#                  paper_sections: List[tuple] = None, sections: Dict[str, str] = None, 
#                  section_summaries: List[str] = None, final_summary: str = ""):
#         self.paper_title = paper_title
#         self.vectorstore = vectorstore
#         self.vectorstore_path = vectorstore_path
#         self.paper_sections = paper_sections or []
#         self.sections = sections or {}
#         self.section_summaries = section_summaries or []
#         self.final_summary = final_summary


class SequentialSummaryAgent:
    """ì—°ì†ì  ì„¹ì…˜ ìš”ì•½ì„ ìˆ˜í–‰í•˜ëŠ” Summary Agent"""
    
    def __init__(self):
        # ê° ì‘ì—…ì— ë§ëŠ” LLM ëª¨ë¸ ì„¤ì •
        self.section_llm = SECTION_SUMMARY_LLM
        self.final_llm = FINAL_SUMMARY_LLM
    
    def create_section_summary_prompt(self, current_section: str, section_name: str, 
                                     previous_summary: str = "", paper_title: str = "") -> str:
        """ì—°ì†ì  ì„¹ì…˜ ìš”ì•½ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        base_prompt = f"""
        You are an expert research analyst summarizing academic papers section by section.

        Paper Title: {paper_title}
        Current Section: {section_name}

        Task: Summarize the current section while maintaining continuity with previous sections.

        Guidelines:
        1. Provide a comprehensive summary of the current section
        2. Connect key points to the overall paper theme
        3. Maintain consistency with previous section summaries
        4. Focus on main contributions, methodology, findings, or arguments
        5. Keep the summary concise but comprehensive

        Current Section Content:
        {current_section}
        """

        if previous_summary:
            continuity_prompt = f"""
            
            Previous Section Summary for Context:
            {previous_summary}

            Please ensure your summary builds upon and connects with the previous content while focusing primarily on the current section.
            """
            base_prompt += continuity_prompt

        # base_prompt += "\n\nProvide your summary in Korean:"
        return base_prompt

    def create_final_summary_prompt(self, section_summaries: List[str], paper_title: str) -> str:
        """ìµœì¢… ìš”ì•½ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        combined_sections = "\n\n".join([f"ì„¹ì…˜ {i+1}: {summary}" for i, summary in enumerate(section_summaries)])
        
        return f"""
        You are an expert research analyst creating a comprehensive final summary of an academic paper.

        Paper Title: {paper_title}

        Based on the following section-by-section summaries, create a comprehensive final summary that includes:

        1. **Research Objective and Background**
        2. **Key Methodology**
        3. **Key Findings**
        4. **Implications and Significance**
        5. **Limitations, if any**

        Section Summaries:
        {combined_sections}

        Please provide a well-structured, comprehensive final summary that synthesizes all sections into a coherent overview of the entire paper.
        """


class SummaryProcessor:
    """Summary ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” ë©”ì¸ í”„ë¡œì„¸ì„œ"""
    
    def __init__(self):
        # ê° ì‘ì—…ì— ë§ëŠ” LLMê³¼ agent ì´ˆê¸°í™”
        self.section_llm = SECTION_SUMMARY_LLM
        self.final_llm = FINAL_SUMMARY_LLM
        self.agent = SequentialSummaryAgent()
        self.file_manager = SummaryFileManager()
    
    @track_agent("extract_sections")
    def extract_sections_optimized(self, state: SummaryState) -> SummaryState:
        """
        ì´ë¯¸ ë¡œë“œëœ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¹ì…˜ë³„ ë‚´ìš© ì¶”ì¶œ
        ë²¡í„°ìŠ¤í† ì–´ ì¬ë¡œë”© ì—†ì´ ê¸°ì¡´ ê²€ì¦ëœ ë¡œì§ ì‚¬ìš©
        """
        paper_title = state["paper_title"]
        vectorstore = state.get("vectorstore")  # ì´ë¯¸ ë¡œë“œëœ ë²¡í„°ìŠ¤í† ì–´ ì‚¬ìš©
        paper_sections = state.get("paper_sections", [])
        
        # ì´ë¯¸ ë¡œë“œëœ ë²¡í„°ìŠ¤í† ì–´ê°€ ì—†ìœ¼ë©´ ì—ëŸ¬
        if vectorstore is None:
            raise ValueError(f"ë²¡í„°ìŠ¤í† ì–´ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {paper_title}")
        
        # ì„¹ì…˜ë³„ ë‚´ìš© ì¶”ì¶œ (ê¸°ì¡´ ê²€ì¦ëœ ë¡œì§ ì‚¬ìš©)
        extracted_sections = {}
        
        if not paper_sections:
            # ì„¹ì…˜ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ì „ì²´ ë¬¸ì„œ ê²€ìƒ‰
            all_docs = vectorstore.similarity_search("", k=100)
            all_content = "\n\n".join([doc.page_content for doc in all_docs])
            extracted_sections["ì „ì²´ ë¬¸ì„œ"] = all_content
        else:
            # ì„¹ì…˜ë³„ë¡œ ë¬¸ì„œ ì¶”ì¶œ (ê¸°ì¡´ ë¡œì§ ê·¸ëŒ€ë¡œ)
            for i, (section_number, section_name) in enumerate(paper_sections, 1):
                try:
                    # í•´ë‹¹ ì„¹ì…˜ì— ì†í•˜ëŠ” ë¬¸ì„œë“¤ ê²€ìƒ‰
                    section_docs = []
                    
                    # vectorstoreì˜ ëª¨ë“  ë¬¸ì„œë¥¼ ê°€ì ¸ì™€ì„œ metadataë¡œ í•„í„°ë§
                    all_docs = vectorstore.similarity_search("", k=1000)
                    
                    for doc in all_docs:
                        doc_metadata = doc.metadata
                        
                        # metadataì—ì„œ section_numberì™€ section ì •ë³´ í™•ì¸
                        doc_section_number = doc_metadata.get("section_number", "")
                        doc_section = doc_metadata.get("section", "")
                        
                        # ì„¹ì…˜ ë²ˆí˜¸ ë˜ëŠ” ì„¹ì…˜ ì´ë¦„ì´ ì¼ì¹˜í•˜ëŠ” ë¬¸ì„œ ìˆ˜ì§‘
                        if (str(doc_section_number) == str(section_number) or 
                            doc_section.strip().lower() == section_name.strip().lower()):
                            section_docs.append(doc)
                    
                    if section_docs:
                        # ì„¹ì…˜ ë¬¸ì„œë“¤ì˜ ë‚´ìš©ì„ ê²°í•©
                        section_content = "\n\n".join([doc.page_content for doc in section_docs])
                        extracted_sections[f"{section_number}. {section_name}"] = section_content
                    else:
                        # ì„¹ì…˜ ì´ë¦„ìœ¼ë¡œ ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹œë„
                        similar_docs = vectorstore.similarity_search(section_name, k=5)
                        if similar_docs:
                            section_content = "\n\n".join([doc.page_content for doc in similar_docs])
                            extracted_sections[f"{section_number}. {section_name}"] = section_content
                        else:
                            extracted_sections[f"{section_number}. {section_name}"] = f"ì„¹ì…˜ '{section_name}'ì— í•´ë‹¹í•˜ëŠ” ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                            
                except Exception as e:
                    extracted_sections[f"{section_number}. {section_name}"] = f"ì„¹ì…˜ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        
        print_completion_message(paper_title, "ì„¹ì…˜ ì¶”ì¶œ", f"{len(extracted_sections)}ê°œ ì„¹ì…˜")
        
        return cast(SummaryState, {
            **state,
            "sections": extracted_sections,
            "section_summaries": [],
            "final_summary": ""
        })
    
    @track_agent("summarize_sections")
    def summarize_sections_sequential(self, state: SummaryState) -> SummaryState:
        """ì„¹ì…˜ë³„ ìˆœì°¨ ìš”ì•½ (ì´ì „ ìš”ì•½ ì»¨í…ìŠ¤íŠ¸ í™œìš©)"""
        # SummaryState êµ¬ì¡°ì— ë§ê²Œ ë°ì´í„° ì¶”ì¶œ
        paper_title = state["paper_title"]  # SummaryStateì—ì„œëŠ” ë‹¨ì¼ ë¬¸ìì—´
        sections = state["sections"]
        paper_sections = state.get("paper_sections", [])  # SummaryStateì—ì„œëŠ” ë¦¬ìŠ¤íŠ¸
        
        # ì„¹ì…˜ ìš”ì•½ ì‹œì‘ ë©”ì‹œì§€
        short_title = paper_title[:50] + "..." if len(paper_title) > 50 else paper_title
        print(f"â³ '{short_title}' ì„¹ì…˜ ìš”ì•½ ì¤‘... ({len(sections)}ê°œ ì„¹ì…˜)")
        
        section_summaries = []
        previous_summary = ""
        
        for i, (section_name, section_content) in enumerate(sections.items(), 1):
            # ì„¹ì…˜ ìš”ì•½ ìƒì„±
            prompt = self.agent.create_section_summary_prompt(
                current_section=section_content,
                section_name=section_name,
                previous_summary=previous_summary,
                paper_title=paper_title
            )
            
            try:
                response = self.section_llm.invoke([
                    SystemMessage(content="You are an expert research analyst."),
                    HumanMessage(content=prompt)
                ])
                
                current_summary = response.content if hasattr(response, 'content') else str(response)
                section_summaries.append(current_summary)
                
                # ì„¹ì…˜ ìš”ì•½ì„ íŒŒì¼ë¡œ ì €ì¥
                if self.file_manager:
                    # ì„¹ì…˜ ë²ˆí˜¸ì™€ ì´ë¦„ ì¶”ì¶œ (ì¸ë±ìŠ¤ ìˆ˜ì •: i-1 ì‚¬ìš©)
                    if (i-1) < len(paper_sections):
                        section_number, section_name_clean = paper_sections[i-1]  # iëŠ” 1ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ i-1
                    else:
                        # paper_sectionsì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ëŠ” ê²½ìš° section_nameì—ì„œ ì¶”ì¶œ
                        parts = section_name.split('. ', 1)
                        if len(parts) == 2:
                            section_number, section_name_clean = parts
                        else:
                            section_number = str(i + 1)
                            section_name_clean = section_name
                    
                    # íŒŒì¼ë¡œ ì €ì¥ (vectorstore_path ì „ë‹¬)
                    self.file_manager.save_section_summary(
                        paper_title=paper_title,
                        section_number=section_number,
                        section_name=section_name_clean,
                        summary_content=current_summary,
                        vectorstore_path=state["vectorstore_path"]
                    )
                
                # ë‹¤ìŒ ì„¹ì…˜ì„ ìœ„í•´ ì´ì „ ìš”ì•½ ì—…ë°ì´íŠ¸ (ìµœê·¼ 2ê°œ ì„¹ì…˜ ìš”ì•½ë§Œ ìœ ì§€)
                if len(section_summaries) >= 2:
                    previous_summary = section_summaries[-1]  # ê°€ì¥ ìµœê·¼ ìš”ì•½ë§Œ ì‚¬ìš©
                elif len(section_summaries) == 1:
                    previous_summary = section_summaries[0]
                    
            except Exception as e:
                error_msg = f"ì„¹ì…˜ '{section_name}' ìš”ì•½ ì¤‘ ì˜¤ë¥˜: {str(e)}"
                section_summaries.append(error_msg)
        
        # ëª¨ë“  ì„¹ì…˜ ìš”ì•½ì„ ì¸ë±ìŠ¤ íŒŒì¼ë¡œ ì €ì¥
        if self.file_manager and section_summaries:
            self.file_manager.save_all_summaries_index(
                paper_title=paper_title,
                section_summaries=section_summaries,
                paper_sections=paper_sections,
                vectorstore_path=state["vectorstore_path"]
            )
        
        print_completion_message(paper_title, "ì„¹ì…˜ë³„ ìš”ì•½", f"{len(section_summaries)}ê°œ ì„¹ì…˜")
        
        return cast(SummaryState, {
            **state,
            "section_summaries": section_summaries
        })
    
    @track_agent("create_final_summary")
    def create_final_summary(self, state: SummaryState) -> SummaryState:
        """ì„¹ì…˜ ìš”ì•½ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ìš”ì•½ ìƒì„±"""
        # SummaryState êµ¬ì¡°ì— ë§ê²Œ ë°ì´í„° ì¶”ì¶œ
        paper_title = state["paper_title"]  # SummaryStateì—ì„œëŠ” ë‹¨ì¼ ë¬¸ìì—´
        section_summaries = state["section_summaries"]
        
        if not section_summaries:
            return cast(SummaryState, {
                **state,
                "final_summary": f"'{paper_title}' ì„¹ì…˜ ìš”ì•½ì´ ì—†ì–´ ìµœì¢… ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            })
        
        prompt = self.agent.create_final_summary_prompt(section_summaries, paper_title)
        
        try:
            response = self.final_llm.invoke([
                SystemMessage(content="You are an expert research analyst specializing in comprehensive paper synthesis."),
                HumanMessage(content=prompt)
            ])
            
            final_summary = response.content if hasattr(response, 'content') else str(response)
            
            # ìµœì¢… ìš”ì•½ì„ íŒŒì¼ë¡œ ì €ì¥
            if self.file_manager:
                self.file_manager.save_final_summary(
                    paper_title=paper_title,
                    final_summary=final_summary,
                    vectorstore_path=state["vectorstore_path"]
                )
            
            print_completion_message(paper_title, "ìµœì¢… ìš”ì•½")
            
            return cast(SummaryState, {
                **state,
                "final_summary": final_summary
            })
            
        except Exception as e:
            error_msg = f"ìµœì¢… ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
            print(f"âŒ '{paper_title}' ìµœì¢… ìš”ì•½ ì˜¤ë¥˜: {error_msg}")
            
            return cast(SummaryState, {
                **state,
                "final_summary": error_msg
            })
    
    # process_single_paper í•¨ìˆ˜ëŠ” ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    # ëŒ€ì‹  run_parallel_summary_processingì—ì„œ ì§ì ‘ SummaryStateë¥¼ ì‚¬ìš©í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    # ì´ëŠ” Stateì™€ SummaryState ê°„ì˜ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.


# def run_parallel_summary_processing(state: State) -> State:
#     """
#     ê·¸ë˜í”„ ë…¸ë“œì—ì„œ ì‚¬ìš©í•  ìµœì¢… ì‹¤í–‰ í•¨ìˆ˜
    
#     Args:
#         state: State - ì²˜ë¦¬í•  ë…¼ë¬¸ë“¤ì˜ ì •ë³´ê°€ ë‹´ê¸´ ë¶€ëª¨ ìƒíƒœ (ì—¬ëŸ¬ ë…¼ë¬¸)
        
#     Returns:
#         State - ìš”ì•½ì´ ì™„ë£Œëœ ìƒíƒœ
#     """
#     # Stateì—ì„œ í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ
#     paper_titles = state["paper_title"]
#     vectorstores = state["vectorstores"]
#     vectorstores_path = state["vectorstores_path"]
#     paper_sections = state.get("paper_sections", {})
#     cache_dir = state.get("cache_dir", "")
    
#     if not paper_titles:
#         logger.warning("âŒ paper_titleì´ ì—†ìŠµë‹ˆë‹¤.")
#         return state
    
#     logger.info(f"ğŸš€ {len(paper_titles)}ê°œ ë…¼ë¬¸ ë³‘ë ¬ ìš”ì•½ ì²˜ë¦¬ ì‹œì‘...")
#     logger.info(f"ğŸ“„ ì²˜ë¦¬ ëŒ€ìƒ ë…¼ë¬¸: {paper_titles}")
    
#     # Summary Processor ì´ˆê¸°í™” (ìì²´ì ìœ¼ë¡œ LLM ê´€ë¦¬)
#     processor = SummaryProcessor()
    
#     # ê° ë…¼ë¬¸ë³„ ê²°ê³¼ ì €ì¥
#     section_summaries = {}
#     final_summary = {}
    
#     # ê° ë…¼ë¬¸ë³„ë¡œ State -> SummaryState ë³€í™˜ í›„ ì²˜ë¦¬
#     for paper_title in paper_titles:
#         # Stateì—ì„œ SummaryState í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ë³€í™˜
#         summary_state: SummaryState = {
#             "paper_title": paper_title,  # ë‹¨ì¼ ë¬¸ìì—´
#             "paper_sections": paper_sections.get(paper_title, []),  # ë¦¬ìŠ¤íŠ¸
#             "vectorstore": vectorstores.get(paper_title),  # ë‹¨ì¼ ê°ì²´
#             "vectorstore_path": vectorstores_path.get(paper_title, ""),  # ë‹¨ì¼ ë¬¸ìì—´
#             "cache_dir": cache_dir,
#             "sections": {},  # ì´ˆê¸°ê°’ (extract_sections_optimizedì—ì„œ ì±„ì›Œì§)
#             "section_summaries": [],  # ì´ˆê¸°ê°’
#             "final_summary": ""  # ì´ˆê¸°ê°’
#         }
        
#         logger.info(f"ğŸ“„ '{paper_title}' ì²˜ë¦¬ ì¤‘...")
        
#         # SummaryStateë¥¼ ì‚¬ìš©í•œ ë‹¨ê³„ë³„ ì²˜ë¦¬
#         try:
#             # 1ë‹¨ê³„: ìµœì í™”ëœ ì„¹ì…˜ ì¶”ì¶œ (ì´ë¯¸ ë¡œë“œëœ ë²¡í„°ìŠ¤í† ì–´ ì‚¬ìš©)
#             summary_state = processor.extract_sections_optimized(summary_state)
            
#             # 2ë‹¨ê³„: ì„¹ì…˜ë³„ ìˆœì°¨ ìš”ì•½
#             summary_state = processor.summarize_sections_sequential(summary_state)
            
#             # 3ë‹¨ê³„: ìµœì¢… ìš”ì•½ ìƒì„±
#             summary_state = processor.create_final_summary(summary_state)
            
#             # ê²°ê³¼ ì €ì¥
#             section_summaries[paper_title] = summary_state["section_summaries"]
#             final_summary[paper_title] = summary_state["final_summary"]
            
#             logger.info(f"âœ… '{paper_title}' ì²˜ë¦¬ ì™„ë£Œ")
            
#         except Exception as e:
#             error_msg = f"'{paper_title}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
#             logger.error(error_msg)
            
#             # ì˜¤ë¥˜ ê²°ê³¼ ì €ì¥
#             section_summaries[paper_title] = [error_msg]
#             final_summary[paper_title] = error_msg
    
#     # ìƒíƒœ ì—…ë°ì´íŠ¸
#     updated_state = {
#         **state,
#         "section_summaries": section_summaries,
#         "final_summary": final_summary
#     }
    
#     logger.info(f"ğŸ¯ ëª¨ë“  ë…¼ë¬¸ ìš”ì•½ ì²˜ë¦¬ ì™„ë£Œ! ì´ {len(paper_titles)}ê°œ ë…¼ë¬¸")
    
#     # ì €ì¥ ê²½ë¡œ ì •ë³´ ì¶œë ¥
#     if cache_dir:
#         logger.info(f"ğŸ’¾ ìš”ì•½ íŒŒì¼ ì €ì¥ ìœ„ì¹˜: {cache_dir}")
#         logger.info(f"   ğŸ“ ê° ë…¼ë¬¸ë³„ë¡œ '[ë…¼ë¬¸ì œëª©]/summaries/' í´ë”ì— ì €ì¥ë¨")
#         logger.info(f"   ğŸ“„ íŒŒì¼ í˜•ì‹: '[ì„¹ì…˜ë²ˆí˜¸] [ì„¹ì…˜ëª…].txt'")
    
#     return updated_state
