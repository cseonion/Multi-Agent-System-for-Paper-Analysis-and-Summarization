from src.state import State
from src.tracking import track_agent
import logging
from langgraph.prebuilt import create_react_agent
from langchain_core.messages import HumanMessage
from agents.tools.web_search import get_web_search_tool
from agents.tools.vectorstore import get_vectorstore_search_tool
from agents.tools.arxiv import get_arxiv_search_tool
from config.agent_llm import get_llm

# í˜„ì¬ ëª¨ë“ˆ ë¡œê±° ìƒì„±
logger = logging.getLogger(__name__)

instructions = """
You are a Literature Review Analysis Agent specialized in synthesizing multiple papers that share a common theme across different domains.
Your role is to extract thematic insights, map the progression of research, and propose future research directions.

# Key Requirements
1. Assume the reader has limited knowledge in at least one domain
2. Briefly explain domain-specific terminology when first introduced
3. Use available tools (web search, vectorstore search, arXiv search) to verify concepts, clarify definitions, provide historical context, and scout recent related works (abstract-level only)
4. Separate technical descriptions from interpretation
5. Present results as a clear, structured report

# Report Structure
- Executive Summary: High-level overview of the shared theme and scope
- Common Themes Identified: Themes recurring across papers with concise evidence
- Research Progression Mapped: How approaches and understanding evolved over time (use web search if publication years are missing)
- Knowledge Gaps Highlighted: Limitations and open problems spanning the theme
- Future Research Directions Suggested: Actionable and realistic next steps (cite abstracts or general sources when helpful)

Tone: Clear, educational, and synthesis-focused. Integrate external info concisely and avoid over-citation.
"""

LIT_REVIEW_LLM = get_llm("lit_review_agent")

@track_agent("lit_review_agent")
def lit_review_agent(state: State) -> State:
    """ë¬¸í—Œ ë¦¬ë·° ì—ì´ì „íŠ¸ (ReAct + Tools, ê³µí†µ ì£¼ì œ / ìƒì´í•œ ë„ë©”ì¸)"""
    paper_domains = state["paper_domain"]
    final_summaries = state["final_summary"]
    vectorstores = state.get("vectorstores", {})

    papers = list(final_summaries.keys())
    logger.info(f"ğŸ“š Literature Review ì‹œì‘: ëŒ€ìƒ ë…¼ë¬¸ ìˆ˜ {len(papers)}")

    # ê° ë…¼ë¬¸ë³„ ë„ë©”ì¸ ì •ë³´ ìˆ˜ì§‘ (í‘œì‹œìš©)
    subfield_map = {}
    for p in papers:
        dom = paper_domains.get(p, {}) or {}
        mlist = dom.get("main_field", []) or []
        sflist = dom.get("sub_field", []) or []
        subfield_map[p] = {"main_field": mlist, "sub_field": sflist}

    # --- Tools êµ¬ì„± ---
    tools = []

    # 1) Web Search Tool (ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©)
    web_tool = get_web_search_tool(max_results=5)
    if web_tool is not None:
        tools.append(web_tool)
        logger.info("ğŸ”§ Web Search Tool í™œì„±í™”")
    else:
        logger.warning("âš ï¸ Web Search Tool ë¹„í™œì„±í™” (ì‚¬ìš© ê°€ëŠ¥í•œ ê²€ìƒ‰ íˆ´ ì—†ìŒ)")

    # 2) Vectorstore Search Tool (ê° ë…¼ë¬¸ë³„ë¡œ ì£¼ì…, ì´ë¦„ êµ¬ë¶„)
    tool_name_map = []  # [(name, paper_title)]
    for idx, p in enumerate(papers, start=1):
        vs = vectorstores.get(p)
        tool_name = f"vectorstore_search_{idx}"
        vs_tool = get_vectorstore_search_tool(vs, p, name=tool_name)
        if vs_tool is not None:
            tools.append(vs_tool)
            tool_name_map.append((tool_name, p))
        else:
            logger.warning(f"âš ï¸ Vectorstore Search Tool ë¹„í™œì„±í™” (ë²¡í„°ìŠ¤í† ì–´ ì—†ìŒ: {p})")

    # 3) arXiv Search Tool (ì´ˆë¡ ìˆ˜ì¤€ ì •ë³´ë§Œ íƒìƒ‰)
    arxiv_tool = get_arxiv_search_tool(max_results=5, sort_by="relevance")
    if arxiv_tool is not None:
        tools.append(arxiv_tool)
        logger.info("ğŸ”§ arXiv Search Tool í™œì„±í™”")
    else:
        logger.warning("âš ï¸ arXiv Search Tool ë¹„í™œì„±í™” (í™˜ê²½ ë˜ëŠ” ì˜ì¡´ì„± ë¬¸ì œ)")

    # --- ReAct Agent ìƒì„± ---
    agent = create_react_agent(LIT_REVIEW_LLM, tools=tools, state_modifier=instructions)

    # ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„± (ì‚¬ìš©ì ë©”ì‹œì§€)
    summaries_block = []
    for i, p in enumerate(papers, start=1):
        summaries_block.append(
            f"Paper {i}: {p}\nMain Fields: {subfield_map[p]['main_field']}\nSub Fields: {subfield_map[p]['sub_field']}\n---\n{final_summaries[p]}\n"
        )
    summaries_text = "\n\n".join(summaries_block)

    tools_hint_lines = ["Tools available:"]
    if web_tool is not None:
        tools_hint_lines.append("- web_search: Use to infer timelines and clarify domain concepts.")
    for name, p in tool_name_map:
        tools_hint_lines.append(f"- {name}: Vector search for '{p}'.")
    if arxiv_tool is not None:
        tools_hint_lines.append("- arxiv: Search for recent related works (abstract-level only).")
    tools_hints = "\n".join(tools_hint_lines)

    prompt = f"""
    Synthesize a literature review across papers that share a common theme but span different domains.

    # All Summaries
    {summaries_text}
    ---------------------------------------
    Follow the instruction and use tools (web search and vectorstore_search) when necessary to improve factual accuracy,
    verify definitions, and extract missing technical context from the source document. If the summary is sufficient, you may proceed without tools.
    *Caution: Do NOT include future research directions (handled by a separate ideation agent).
    """

    try:
        logger.info("ğŸ” ReAct ì—ì´ì „íŠ¸ ì‹¤í–‰ (tool ì‚¬ìš© ê°€ëŠ¥, ë¬¸í—Œ ë¦¬ë·°)...")
        result = agent.invoke({"messages": [HumanMessage(content=prompt)]})
        messages = result.get("messages", []) if isinstance(result, dict) else []
        if messages:
            analysis_report = messages[-1].content
        else:
            analysis_report = str(result)

        logger.info("âœ… Literature Review ì™„ë£Œ")
        logger.debug(f"ë¶„ì„ ê²°ê³¼ ê¸¸ì´: {len(analysis_report)} ë¬¸ì")

        return {
            **state,
            "analysis_report": analysis_report
        }

    except Exception as e:
        error_msg = f"ë¬¸í—Œ ë¦¬ë·° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(f"âŒ {error_msg}")
        return {
            **state,
            "analysis_report": f"ë¬¸í—Œ ë¦¬ë·° ì˜¤ë¥˜: {error_msg}"
        }